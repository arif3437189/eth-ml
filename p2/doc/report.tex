\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Machine Learning 2015: Project 2 - Regression Report}
\author{pungast@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section*{Experimental Protocol}
I added nonlinear features to the original features and used a Random Forest classifier to predict the 3 classes.

\section{Tools}
I used Python with scikit-learn 0.17. Source code is attached to the submission.

\section{Algorithm}
I used Random Forest with (max_depth=None, max_features=2, min_samples_split=5, n_estimators=40

\section{Features}
I added the following new features, for each feature x: $log x$, $x log x$, $\sqrt{x}$, $x^3$, $x^4$ and all second-order polynomial combinations of features.

I did not normalise the data because it turned out that neither row-max normalising (dividing all features of each datapoint by the maximum dimension) or column-max normalising (diving all i-th feature values with the maximum i-th feature over all datapoints) improved prediction accuracy in cross-validation.

For visualising the data (for debugging and getting an overview of the data) I used the t-SNE algorithm to map the datapoints into 2 dimensions so that locality information would be conserved. The result is depicted in Figure~\ref{fig:tsne} and shows that the datapoints are quite well linearly separable even in the 2-dimensional space resulting from applying t-SNE.

\begin{figure}[h]
	\label{fig:tsne}
	\begin{center}
	\includegraphics[width=\textwidth]{failures1}
	\end{center}
\end{figure}

\section{Parameters}
How did you find the parameters of your model? (What parameters have you searched over, cross validation procedure, $\ldots$)

\section{Lessons Learned} What other algorithms, tools or methods did you try out that didn't work well?
Why do you think they performed worse than what you used for your final submission?

I also tried SVMs with different kernels (RBF, polynomial, linear) but they were all beat by Random Forest in cross-validated parameter searches.

\end{document}
