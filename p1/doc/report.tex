\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Machine Learning 2015: Project 1 - Regression Report}
\author{pungast@student.ethz.ch}
\date{\today}

\begin{document}
\maketitle

\section*{Experimental Protocol}

To obtain the model from raw feature vector $X = (x_1, ..., x_n)$, the following steps were taken. Each step was applied to the result of last step.

\begin{enumerate}
	\item A subset of the original features were removed. Selection criteria were similar to those laid out in Step 5.
	\item Nonlinear combinations of the features were added (described in Section~\ref{sec:features}).
	\item Features were normalised by subtracting the mean and dividing by the standard deviation.
	\item A bias term $x_0$ was added to the data.
	\item Redundant features were identified by removing each feature $x_i$, running 10-fold cross-validation on features $X' = X \setminus x_i$. A feature was declared redundant if the mean RMSE from cross-validation on features $X'$ decreased by $0.05$ or more compared to using all features.
	\item A \textbf{ridge regression} model with normalisation parameter $\lambda=0.1$ was trained. The value of $\lambda$ was selected in 10-fold cross-validation to produce the lowest mean RMSE.
	\item Weights $(w_0,...w_n)$ of the model were used to find the predicted value $y = \sum_{i=0}^{n} w_i x_i$.
\end{enumerate}

\section{Tools}
I used:

\begin{itemize}
	\item Python 2.7
	\item scikit-learn for training a LASSO classifier
	\item NumPy for everything else
\end{itemize}

All code used for this project is wrapped into a single class in \verb+Regressor.py+.

\section{Algorithm}
Ridge regression was chosen as the best model in this project.

\section{Features}
The following features were added:
\label{sec:features}
\begin{itemize}
		\item bias term $x_0=1$
		\item $log(1 + x_i)$
		\item $x_i log(x_i)$
		\item $\sqrt{x_i}$
		\item $x_i x_j$ for all $i,j \in \{1,...,n\}$
		\item $x_i^3$
		\item $x_i^4$
	\end{itemize}

\section{Parameters}
To find the hyperparameter $\lambda$ of ridge regression, I used 10-fold cross-validation, testing values of lambda ranging from 0.01 to 10000, with each tested lambda value roughly 3 times larger than the previous one ($[0.01, 0.03, 0.1, ...]$). The goal was the lowest mean RMSE over all 10 folds.

\section{Lessons Learned}
In addition to ridge regression, I tested LASSO regression. The CV error for LASSO was higher than for ridge regression. However, I did not conduct a formal parameter sweep (for LASSO) since ridge regression already had a quite low RMSE of $670$. It is entirely possible that LASSO would perform better given the right regularisation parameter.

At the start of the project, it was clear that adding nonlinear features decreased the RMSE on the training set. However, with too many features the model overfit (CV error was high while training error was low). Conclusion: it is very important to remove redundant features to avoid overfitting the model.

\end{document}
